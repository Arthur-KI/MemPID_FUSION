# MemPID_FUSION

```
â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— 
â–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—
â–ˆâ–ˆâ•”â–ˆâ–ˆâ–ˆâ–ˆâ•”â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•”â–ˆâ–ˆâ–ˆâ–ˆâ•”â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘
â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â• â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘
â–ˆâ–ˆâ•‘ â•šâ•â• â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘ â•šâ•â• â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•
â•šâ•â•     â•šâ•â•â•šâ•â•â•â•â•â•â•â•šâ•â•     â•šâ•â•â•šâ•â•     â•šâ•â•â•šâ•â•â•â•â•â• 
                â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—   â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ•—
                â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•‘
                â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â–ˆâ–ˆâ•— â–ˆâ–ˆâ•‘
                â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â•šâ•â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘
                â–ˆâ–ˆâ•‘     â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘ â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•‘
                â•šâ•â•      â•šâ•â•â•â•â•â• â•šâ•â•â•â•â•â•â•â•šâ•â• â•šâ•â•â•â•â•â• â•šâ•â•  â•šâ•â•â•â•
```

> **A novel language model architecture using PID controllers instead of attention. No O(nÂ²) - just O(n)!**

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)

---

## ğŸ†• What's New in v3

| Feature | v1 | v3 |
|---------|----|----|
| **Multi-Head Importance Pool** | âŒ Mean Pool | âœ… 4 learned "editors" |
| **Adaptive Decay** | âŒ Static | âœ… Content-aware forgetting |
| **Dimensions** | 512 | 1024 |
| **Context Window** | 512 tokens | 2048 tokens |
| **Parameters** | ~28M | ~128M |
| **Coherent Generation** | ~200 tokens | **300-500 tokens** |

---

## ğŸ§  What is MemPID_FUSION?

MemPID_FUSION is an experimental language model that replaces the traditional **Attention mechanism** with **PID controllers** (Proportional-Integral-Derivative) from control theory.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Traditional Transformer    vs    MemPID_FUSION             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  [Attention O(nÂ²)]              [PID Gates O(n)]            â”‚
â”‚       â†“                              â†“                      â”‚
â”‚  Expensive for                  Linear complexity!          â”‚
â”‚  long sequences                 Efficient memory!           â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âœ¨ Key Features

| Feature | Description |
|---------|-------------|
| ğŸš« **No Attention** | O(n) complexity instead of O(nÂ²) |
| ğŸ›ï¸ **PID Controllers** | Learnable Kp, Ki, Kd per dimension |
| ğŸ¯ **Multi-Head Importance Pool** | 4 heads learn what's important (NEW!) |
| ğŸŒŠ **Adaptive Decay** | Content-aware forgetting (NEW!) |
| ğŸ›£ï¸ **Highway Connections** | Up â†’ Down â†’ Up architecture |
| âš¡ **Efficient** | ~128M params, runs on consumer GPUs |

---

## ğŸ¯ Multi-Head Importance Pool (New in v3!)

The key innovation of v3: Instead of treating all tokens equally, the model learns **what's important**.

```
The Problem with Mean Pooling:
  [King, uh, the, well, daughter] â†’ all weighted equally
  â†’ "uh" dilutes "King" â†’ fuzzy context

The Solution - Importance Pool:
  [King, uh, the, well, daughter]
     â†“     â†“    â†“    â†“      â†“
   0.35  0.02 0.08 0.03   0.32  â† Learned weights!
  â†’ Important tokens dominate, noise is ignored
```

**4 Heads = 4 "Editors"**, each specializing in different aspects:
- Head 1 â†’ Subjects/Nouns
- Head 2 â†’ Verbs/Actions  
- Head 3 â†’ Negations/Modifiers
- Head 4 â†’ Noise Filter

**Still O(n)!** Uses cumsum trick instead of attention matrix.

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MemPID_FUSION v3 Block                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  Input                                                      â”‚
â”‚    â†“                                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                            â”‚
â”‚  â”‚   RMSNorm   â”‚  â† Pre-normalization                       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                                            â”‚
â”‚         â†“                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚  â”‚    Causal Dilated Convolution       â”‚                    â”‚
â”‚  â”‚    (kernel=64, dilations=1â†’32)      â”‚                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚         â†“                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚  â”‚      Adaptive PID Memory Gate       â”‚                    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”  â”‚                    â”‚
â”‚  â”‚  â”‚ Kp  â”‚ â”‚ Ki  â”‚ â”‚ Kd  â”‚ â”‚ Decay â”‚  â”‚ â† All learnable!   â”‚
â”‚  â”‚  â””â”€â”€â”¬â”€â”€â”˜ â””â”€â”€â”¬â”€â”€â”˜ â””â”€â”€â”¬â”€â”€â”˜ â””â”€â”€â”€â”¬â”€â”€â”€â”˜  â”‚                    â”‚
â”‚  â”‚     â†“       â†“       â†“        â†“      â”‚                    â”‚
â”‚  â”‚   P-Term  I-Term  D-Term  Adaptive  â”‚                    â”‚
â”‚  â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚                    â”‚
â”‚  â”‚              â†“                      â”‚                    â”‚
â”‚  â”‚        Gated Output                 â”‚                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚         â†“                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚  â”‚    Multi-Head Importance Pool       â”‚  â† NEW in v3!      â”‚
â”‚  â”‚    (4 heads, cumsum trick, O(n))    â”‚                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚         â†“                                                   â”‚
â”‚  Output + Residual                                          â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Up-Down-Up     â”‚
                    â”‚  Highway        â”‚
                    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                    â”‚  Up Stack (6L)  â”‚
                    â”‚       â†“         â”‚
                    â”‚  Gate + Skip    â”‚
                    â”‚       â†“         â”‚
                    â”‚  Down Stack(6L) â”‚
                    â”‚       â†“         â”‚
                    â”‚  Gate + Skip    â”‚
                    â”‚       â†“         â”‚
                    â”‚  Up Stack (6L)  â”‚
                    â”‚       â†“         â”‚
                    â”‚  Final Gate     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ›ï¸ The PID Controller

Each dimension has its own PID controller with **adaptive decay**:

```python
# PID Gate with Adaptive Decay
P_term = Kp * current_state           # Present (react now)
I_term = Ki * integral_state          # Past (accumulated memory)  
D_term = Kd * (current - previous)    # Change (detect transitions)

# NEW: Content-aware decay
decay = sigmoid(base_decay + content_signal)
new_integral = decay * old_integral + (1 - decay) * current

output = silu(P_term + I_term + D_term) * input
```

| Term | Function | What it learns |
|------|----------|----------------|
| **P** (Proportional) | React to current input | Immediate patterns |
| **I** (Integral) | Accumulate over time | Long-term context |
| **D** (Derivative) | Detect changes | Transitions, surprises |
| **Decay** | Adaptive forgetting | When to remember/forget |

---

## ğŸ“Š Model Specifications

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MemPID_FUSION v3                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Parameters:     ~128M                  â”‚
â”‚  Dimensions:     1024                   â”‚
â”‚  Layers:         6 per stack (Ã—3)       â”‚
â”‚  Vocab Size:     16,000 (BPE)           â”‚
â”‚  Context:        2048 tokens            â”‚
â”‚  Importance:     4 heads                â”‚
â”‚  Precision:      bfloat16               â”‚
â”‚  Val Loss:       ~4.03                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Installation

```bash
# Clone repository
git clone https://github.com/Arthur-KI/MemPID_FUSION.git
cd MemPID_FUSION

# Install dependencies
pip install -r requirements.txt
```

### Requirements

```
torch>=2.0
numpy
tqdm
tokenizers
```

---

## ğŸ’» Usage

### Training

```bash
# Prepare your data in training_data/ folder
# Each subfolder becomes a category token: training_data/classics/ â†’ <CLASSICS>

python training_MemPID_FUSION_v3.py
```

### Chat / Inference

```bash
python chat_fusion_v3.py
```

Choose from:
1. ğŸ’¬ Interactive Chat
2. ğŸ§ª Quick Test (all categories)
3. ğŸ“œ Long Context Test (500 tokens)

---

## ğŸ“ Meta-Tokens

The model uses special tokens to control output style:

| Token | Style |
|-------|-------|
| `<KLASSIKER>` | Classical German literature |
| `<PHILOSOPHIE>` | Philosophical writing |
| `<LYRIK>` | Poetry |
| `<WISSEN>` | Encyclopedia/Facts |
| `<GESETZE>` | Legal texts |

---

## ğŸ“ˆ Results

| Metric | v1 | v3 |
|--------|----|----|
| Val Loss | 3.85 | 4.03 |
| Coherent tokens | ~200 | **300-500** |
| Grammar | âœ… | âœ… |
| Style differentiation | âœ… | âœ… |
| Long-range coherence | âš ï¸ | âœ… |
| Factual accuracy | âŒ | âŒ (limited by size) |

**Note:** Higher loss but better coherence! The Importance Pool successfully filters noise.

---

## ğŸ”¬ Why PID instead of Attention?

| Aspect | Attention | PID |
|--------|-----------|-----|
| Complexity | O(nÂ²) | **O(n)** |
| Memory | High | Low |
| Long sequences | Expensive | Efficient |
| Interpretability | Black box | Control theory! |

The hypothesis: PID controllers can learn to regulate information flow similarly to attention, but with explicit temporal dynamics (P=present, I=past, D=change) and **linear complexity**.

---

## ğŸ“ Project Structure

```
MemPID_FUSION/
â”œâ”€â”€ training_MemPID_FUSION_v2.py   # Training + Model Definition
â”œâ”€â”€ chat_fusion_v2.py              # Inference / Interactive Chat
â”œâ”€â”€ requirements.txt               # Dependencies
â”œâ”€â”€ CHANGELOG.md                   # Version history
â”œâ”€â”€ LICENSE.txt                    # MIT License
â””â”€â”€ README.md                      # This file
```

---

## ğŸ—ºï¸ Roadmap

- [x] v1: Basic PID architecture (28M params)
- [x] v3: Multi-Head Importance Pool + Adaptive Decay (128M params)
- [ ] 500M parameter version
- [ ] Benchmarks against GPT-2

---

## ğŸ¤ Contributing

Contributions welcome! Feel free to:
- Open issues
- Submit pull requests
- Share your experiments
- Train on different data

---

## ğŸ“œ License

This project is licensed under the MIT License - see the [LICENSE.txt](LICENSE.txt) file.

---

## ğŸ“– Citation

```bibtex
@software{mempid_fusion,
  author = {Arthur-KI},
  title = {MemPID_FUSION: Language Model with PID Controllers},
  year = {2025},
  url = {https://github.com/Arthur-KI/MemPID_FUSION}
}
```

---

## ğŸ™ Acknowledgments

This project was created through human-AI collaboration:

- **Arthur** - Vision, ideas, training, testing
- **Claude (Anthropic)** - Architecture design, code, documentation
- **Gemini Pro (Google)** - Analysis, cumsum O(n) fix, data strategy

Proof that curiosity beats credentials! Built without formal CS education.

---

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚   "No Attention? No Problem."                               â”‚
â”‚                                        - MemPID_FUSION      â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```
